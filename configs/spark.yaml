# DGX Spark — Best UX, Full Pipeline
# VRAM: 128GB unified | Target E2E: <700ms
#
# 7B VLM + Kokoro TTS + Nemotron STT
# Same pipeline as Thor but on DGX Spark (Blackwell GB10).
# Uses standard PyTorch (not Jetson AI Lab wheels).
#
# Prerequisites:
#   docker compose -f docker-compose.spark.yml up -d   # starts vLLM 7B
#   apt-get install espeak-ng                           # required by Kokoro
#   pip install -e ".[kokoro,nemotron,assistant,vision]"
#
# Usage:
#   jetson-assistant assistant --config configs/spark.yaml
#   jetson-assistant assistant --auto   # auto-detects Spark and uses this

# TTS: Natural tier (near-human prosody, <300ms)
tts_backend: kokoro
tts_voice: af_heart

# STT: Accurate tier (low WER, handles names, ~24ms)
stt_backend: nemotron

# VLM: Full tier (7B NVFP4 quantized — same as Thor, faster inference)
llm_backend: vllm
llm_host: "http://localhost:8001/v1"
llm_model: "nvidia/Qwen2.5-VL-7B-Instruct-NVFP4"

# Vision: camera + MJPEG browser stream
vision_enabled: true
stream_vision_port: 9090

# Always listening (no wake word model needed)
wake_word_backend: energy

# Show timing info
verbose: true
