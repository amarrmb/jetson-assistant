# Jetson AGX Orin â€” Natural UX, Vision Capable
# VRAM: 32-64GB | Target E2E: <1s
#
# 3B VLM + Kokoro TTS + Nemotron STT
# Smaller VLM fits in 32GB; still natural voice + fast STT.
#
# Prerequisites:
#   docker compose -f docker-compose.orin.yml up -d   # starts vLLM 3B
#   apt-get install espeak-ng                          # required by Kokoro
#   pip install -e ".[kokoro,nemotron,assistant,vision]"
#
# Usage:
#   jetson-assistant assistant --config configs/orin.yaml
#   jetson-assistant assistant --auto   # auto-detects Orin and uses this

# TTS: Natural tier (near-human prosody, <300ms)
tts_backend: kokoro
tts_voice: af_heart

# STT: Accurate tier (low WER, handles names, ~24ms)
stt_backend: nemotron

# VLM: Mid tier (3B vision-language model, fits 32GB)
llm_backend: vllm
llm_host: "http://localhost:8001/v1"
llm_model: "Qwen/Qwen2.5-VL-3B-Instruct"

# Vision: camera + MJPEG browser stream
vision_enabled: true
stream_vision_port: 9090

# Always listening (no wake word model needed)
wake_word_backend: energy

# Show timing info
verbose: true
